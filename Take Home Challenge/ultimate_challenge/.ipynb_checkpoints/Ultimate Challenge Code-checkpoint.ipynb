{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logins = pd.read_json('logins.json')\n",
    "logins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logins.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "login_time is already of type datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logins.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "login time spans around 4 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logins.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logins.sort_values('login_time').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation into 15 minute Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = logins.resample('15Min', on='login_time').count()\n",
    "interval.columns = ['count']\n",
    "interval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing logins over different time frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(interval['count'], binwidth=5)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.title('Distribution of 15-Minute Time Interval Log-in Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of our 15 minute intervals had login counts between 0 - 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,5])\n",
    "plt.plot(interval)\n",
    "plt.title('Login Counts Over Entire Period')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there big spikes in the number of logins\n",
    "\n",
    "Let's take a closer look at daily time period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Login counts for each day of the week**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval['week']=interval.index.week\n",
    "interval['day']=interval.index.day\n",
    "interval['day_of_week'] = interval.index.dayofweek # Monday starts at index 0\n",
    "interval['hour'] = interval.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval.groupby('day_of_week')['count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.lineplot(x='week', y='count', data=interval)\n",
    "plt.title('Mean Login Count Each Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Are there certain days each month that we see a boost in logins?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "January = interval['1970-01-01': '1970-01-31']\n",
    "February = interval['1970-02-01':'1970-02-28']\n",
    "March = interval['1970-03-01':'1970-03-31']\n",
    "April = interval['1970-04-01':interval.index.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, figsize=(15,8), sharey=True, sharex=True)\n",
    "\n",
    "sns.lineplot(x='day', y='count', data=January, ax=axes[0][0])\n",
    "axes[0][0].set_title('January')\n",
    "\n",
    "sns.lineplot(x='day', y='count', data=February, ax=axes[0][1])\n",
    "axes[0][1].set_title('February')\n",
    "\n",
    "sns.lineplot(x='day', y='count', data=March, ax=axes[1][0])\n",
    "axes[1][0].set_title('March')\n",
    "\n",
    "sns.lineplot(x='day', y='count', data=April, ax=axes[1][1])\n",
    "axes[1][1].set_title('April')\n",
    "\n",
    "fig.suptitle('Daily Average Login Count for Each Month', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "sns.lineplot(x='day_of_week', y='count', data=interval, ci=None, ax=ax1)\n",
    "ax1.set_xticks(range(7))\n",
    "ax1.set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "ax1.set_ylabel('mean count')\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='day_of_week', y='count', data=interval, ax=ax2)\n",
    "ax2.set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "plt.suptitle('Login Counts Per Day of Week', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an increase in Login Counts as we approach the weekend with a spike when the weekend hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x='hour', y='count', data=interval, ci=None)\n",
    "plt.xticks(range(24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a steep drop in login counts from 6am to 9am and minor drop again from 1 pm to 7pm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Experiment and Metrics Design\n",
    "The neighboring cities of Gotham and Metropolis have complementary circadian rhythms: on\n",
    "weekdays, Ultimate Gotham is most active at night, and Ultimate Metropolis is most active\n",
    "during the day. On weekends, there is reasonable activity in both cities.\n",
    "\n",
    "However, a toll bridge, with a two-way toll, between the two cities causes driver partners to tend\n",
    "to be exclusive to each city. The Ultimate managers of city operations for the two cities have\n",
    "proposed an experiment to encourage driver partners to be available in both cities, by\n",
    "reimbursing all toll costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  What would you choose as the key measure of success of this experiment in\n",
    "encouraging driver partners to serve both cities, and why would you choose this metric?**\n",
    "\n",
    "Assuming that Ultimate drivers utilize an app of some sort, we can use the geolocation data from the app and count the total times a driver crosses the bridge into the other city. Since, the goal is to get our driver partners available in both cities, tallying the number of times they cross into the other city each day will reveal if drivers are taking rides in the other city. And for those drivers that do, the metric will tell us how many trips they are making between each city . \n",
    "\n",
    "**2. Describe a practical experiment you would design to compare the effectiveness of the proposed change in relation to the key measure of success. Please provide details on:**\n",
    "\n",
    "**a.) how you will implement the experiment**\n",
    "\n",
    "First create a group of the drivers who drive exclusively to one city. \n",
    "From this group, create two randomly selected roughly equal in size sub groups:\n",
    "Drivers who continue to not receive refunds for tolls\n",
    "Drivers who have been notified that they will receive a refund for toll crossings\n",
    "\n",
    "**b.) what statistical test(s) you will conduct to verify the significance of the observation?**\n",
    "\n",
    "Hypothesis testing (A/B testing): Randomized controlled experiment comparing the means of key metrics between our two groups\n",
    "Null hypothesis: there is no statistically significant difference between the means of the  two groups\n",
    "Alternative Hypothesis: There is a statistically significant difference between our control group and the refund group\n",
    "\n",
    "**c.) how you would interpret the results and provide recommendations to the city operations team along with any caveats**\n",
    "\n",
    "If the p-value is less than a significance level threshold  of 0.05, we can reject the null hypothesis. This would mean that it is very likely that issuing refunds indeed encourages drivers to take riders in other cities. We could recommend this alternative hypothesis after a few more experiments. We would also recommend that the city operations team review some potential caveats for making any decisions\n",
    "\n",
    "Caveats:\n",
    "\n",
    "* Just because a driver crosses the bridge frequently doesnâ€™t mean they are assigned many trips. It could be that drivers are just making many inter-city trips, or that a driver is simply crossing the bridge without taking a trip. \n",
    "* Another metric such as total time in other city = `trips in other city x avg(duration of a trip)` should also be considered\n",
    "* Need to ensure that the costs of refunding toll bridges does not outweigh the additional generated revenue of drivers taking more trips in the other city. Ultimate would want drivers to stay in highly active areas once there.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('ultimate_data_challenge.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are missing values for 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_rating_of_driver'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_rating_by_driver'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values for these two columns are concentrated, so let's impute uisng median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_rating_of_driver'].fillna(df['avg_rating_of_driver'].median(), inplace=True)\n",
    "df['avg_rating_by_driver'].fillna(df['avg_rating_by_driver'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'phone' column is a categorical variable. Let's impute with NA for now\n",
    "df['phone'] = df['phone'].fillna('No Info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Retention Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change date columns to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['signup_date','last_trip_date']] = df[['signup_date','last_trip_date']].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.last_trip_date.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last recorded date is July 1. Let's take all observations with last trip date between July 1 and 30 days before July 1 and label them as active users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = df.last_trip_date.max() - timedelta(days=30) #cut off date for active user\n",
    "\n",
    "df['retained'] = df['last_trip_date'].apply(lambda x: True if x>=cutoff else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['retained'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['retained']==True).sum() / len((df['retained']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More users are inactive than active as defined by Ultimate's criteria. Only 37.6% of the total users are retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap of Correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some correlation exists between `ultimate_black_user`, `trip_in_first_30_days`, and our target variable `retained`\n",
    "\n",
    "There is also high pairwise correlation between `avg_surge` and `surge_pct`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore some of these variables more by looking at their distributions while considering retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trips in the first 30 days**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='retained', y='trips_in_first_30_days', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retained users are slighlty more likely to take more trips in their first 30 days. There are outliers for both groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ultimate Black User**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='ultimate_black_user', data=df, hue='retained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-ultimate black  users are less likely to be retained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**City user signed up in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='city', data=df, hue='retained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users who signed up in King's landing were more likely to be retained than not retained. Astapor City and Winterfell experience many users who do not continue with the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primary phone device for user**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='phone', data=df, hue='retained')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage wise, android users have a lower retention rate. Could there be something wrong in how our android app interface?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling\n",
    "\n",
    "Let's try two classification alogorithms: linear and tree based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modeling\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change categorical variables into numeric through dummy variable encoding\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns for X column\n",
    "X = df.drop(['last_trip_date', 'signup_date', 'retained'], axis=1)\n",
    "y = df['retained']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scoring Report Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(columns=['accuracy','precision','recall','f1_score','auc_score'])\n",
    "\n",
    "def score_model(model_name, y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 =  f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    score_df.loc[model_name,:] = accuracy, precision, recall, f1, auc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_pred = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model('dummy', y_test, y_pred)\n",
    "score_df.iloc[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Pipeline(steps=[('scaler', StandardScaler()), ('clf',LogisticRegression())]) # pipeline of transform w/ final estimator\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model('lr', y_test, y_pred)\n",
    "score_df.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lr, X_test, y_test, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'clf__C':[0.001, 0.01, .01, 1, 10, 100], \n",
    "              'clf__class_weight':['balanced',None]}\n",
    "\n",
    "pipe = Pipeline(steps=[('scaler', StandardScaler()), ('clf',LogisticRegression())])\n",
    "lr_tuned = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "\n",
    "lr_tuned.fit(X_train, y_train)\n",
    "y_pred = lr_tuned.predict(X_test)\n",
    "\n",
    "print('best hyperparameters:', lr_tuned.best_params_)\n",
    "score_model('lr_tuned', y_test, y_pred)\n",
    "score_df.iloc[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "score_model('rf', y_test, y_pred)\n",
    "score_df.iloc[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[int(x) for x in np.linspace(start=100, stop=1000, num=10)],\n",
    "             'max_depth':[int(x) for x in np.linspace(5, 25, num=5)],\n",
    "             'min_samples_split':np.arange(2, 12, 2), # mininum number of samples required to split a node\n",
    "             'min_samples_leaf': np.arange(2, 12, 2), # minimum number of samples required for a leaf node\n",
    "             'max_features': np.arange(2, 12, 2)}\n",
    "\n",
    "rf_tuned = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, cv=5, n_jobs=-1, n_iter=250)\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "y_pred = rf_tuned.predict(X_test)\n",
    "\n",
    "score_model('rf_tuned', y_test, y_pred)\n",
    "score_df.iloc[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimate can use the model to predict which users are at risk of becoming non-active and then use that information to target them with advertisements and promotions to encourage them to reuse the app. Ulimate could also send promotions or surveys to the active users to understand why they use their service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
